{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc0e788",
   "metadata": {},
   "source": [
    "# Laboratory Task 2 – Forward Pass\n",
    "\n",
    "**Name:** Joanna Reyda Santos  \n",
    "**Section:** DS4A  \n",
    "\n",
    "**Instruction:** Perform a single forward pass and compute for the error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c64ab",
   "metadata": {},
   "source": [
    "#### Given Parameters\n",
    "\n",
    "$$\n",
    "x = \n",
    "\\begin{bmatrix}\n",
    "1 \\\\ \n",
    "0 \\\\ \n",
    "1\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "y = [1],\n",
    "\\quad\n",
    "f(z) = \\max(0, z)\n",
    "$$\n",
    "\n",
    "\n",
    "#### Hidden Unit Weights\n",
    "\n",
    "$$\n",
    "W_h =\n",
    "\\begin{bmatrix}\n",
    "w_{11} = 0.2 & w_{12} = -0.3 \\\\\n",
    "w_{13} = 0.4 & w_{14} = 0.1 \\\\\n",
    "w_{15} = -0.5 & w_{16} = 0.2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Output Weights\n",
    "\n",
    "$$\n",
    "W_o =\n",
    "\\begin{bmatrix}\n",
    "w_{21} = -0.3 \\\\\n",
    "w_{22} = -0.2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Biases\n",
    "\n",
    "$$\n",
    "\\theta_1 = -0.4, \\quad\n",
    "\\theta_2 = 0.2, \\quad\n",
    "\\theta_3 = 0.1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4c621f",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "##### Hidden Layer\n",
    "\n",
    "Compute each hidden unit pre-activation:\n",
    "\n",
    "$$\n",
    "z_1 = (1)(0.2) + (0)(0.4) + (1)(-0.5) + (-0.4) = -0.7\n",
    "$$\n",
    "\n",
    "$$\n",
    "z_2 = (1)(-0.3) + (0)(0.1) + (1)(0.2) + (0.2) = 0.1\n",
    "$$\n",
    "\n",
    "Apply activation \\( a_i = f(z_i) = \\max(0, z_i) \\):\n",
    "\n",
    "$$\n",
    "a_1 = f(-0.7) = 0, \\quad a_2 = f(0.1) = 0.1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22cb8ef",
   "metadata": {},
   "source": [
    "##### Output Layer\n",
    "\n",
    "$$\n",
    "z_3 = (a_1)(-0.3) + (a_2)(-0.2) + (0.1) = 0.08\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y} = f(z_3) = f(0.08) = 0.08\n",
    "$$\n",
    "\n",
    "##### Error Calculation\n",
    "\n",
    "$$\n",
    "E = \\frac{1}{2}(y - \\hat{y})^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "E = \\frac{1}{2}(1 - 0.08)^2 = 0.4232\n",
    "$$\n",
    "\n",
    "\n",
    "##### Final Results\n",
    "\n",
    "$$\n",
    "\\hat{y} = 0.08, \\quad E = 0.4232\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5217be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1 = -0.70, z2 = 0.10\n",
      "h1 = 0.00, h2 = 0.10\n",
      "z3 = 0.08\n",
      "Predicted Output (ŷ) = 0.08\n",
      "Error (E) = 0.4232\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Input and target\n",
    "x = np.array([1, 0, 1])\n",
    "y = np.array([1])\n",
    "\n",
    "# ReLU activation\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "# Hidden layer\n",
    "z1 = (1*0.2) + (0*0.4) + (1*-0.5) + (-0.4)\n",
    "z2 = (1*-0.3) + (0*0.1) + (1*0.2) + (0.2)\n",
    "\n",
    "h1, h2 = relu(z1), relu(z2)\n",
    "\n",
    "# Output layer\n",
    "z3 = (h1*-0.3) + (h2*-0.2) + (0.1)\n",
    "y_hat = relu(z3)\n",
    "\n",
    "# Error\n",
    "E = 0.5 * (y - y_hat)**2\n",
    "\n",
    "print(f\"z1 = {z1:.2f}, z2 = {z2:.2f}\")\n",
    "print(f\"h1 = {h1:.2f}, h2 = {h2:.2f}\")\n",
    "print(f\"z3 = {z3:.2f}\")\n",
    "print(f\"Predicted Output (ŷ) = {y_hat:.2f}\")\n",
    "print(f\"Error (E) = {E[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51103f0",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "\n",
    "In this activity, I performed a single forward pass through a simple neural network using the ReLU activation function. \n",
    "By manually computing each step and verifying with Python, I saw how the weights, biases, and activation function \n",
    "determine the output prediction. The error value \\( E = 0.4232 \\) shows that the network’s output (0.08) \n",
    "is far from the target (1), which will later be corrected through backpropagation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
